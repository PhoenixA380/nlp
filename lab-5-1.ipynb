{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing packages\n",
    "([Go to top](#Lab-5.1:-Implementing-Information-Extraction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install smart_open\n",
    "!pip install networkx\n",
    "!pip install pandas\n",
    "!pip install pyvis\n",
    "!pip install spacy\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import uuid\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import smart_open\n",
    "\n",
    "from time import sleep\n",
    "from matplotlib import cm, colors\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing the documents to Amazon S3\n",
    "([Go to top](#Lab-5.1:-Implementing-Information-Extraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"c137242a3503183l8793306t1w240511328416-labbucket-pjsjzjy5y28n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client and session information\n",
    "session = boto3.Session()\n",
    "s3_client = session.client(service_name=\"s3\")\n",
    "\n",
    "# Constants for S3 bucket and input data file\n",
    "\n",
    "filename = \"sample_finance_dataset.txt\"\n",
    "input_data_s3_path = f's3://{bucket}/' + filename\n",
    "output_data_s3_path = f's3://{bucket}/'\n",
    "\n",
    "# Upload the local file to S3\n",
    "s3_client.upload_file(\"../data/\" + filename, bucket, filename)\n",
    "\n",
    "# Load the documents locally for later analysis\n",
    "with open(\"../data/\" + filename, \"r\") as fi:\n",
    "    raw_texts = [line.strip() for line in fi.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Starting an asynchronous events detection job using the SDK\n",
    "([Go to top](#Lab-5.1:-Implementing-Information-Extraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon Comprehend client information\n",
    "comprehend_client = session.client(service_name=\"comprehend\")\n",
    "\n",
    "# IAM role with access to Amazon Comprehend and the specified S3 bucket\n",
    "job_data_access_role = 'arn:aws:iam::240511328416:role/service-role/c137242a3503183l8793306t1w-ComprehendDataAccessRole-nYPAP3doCDUJ'\n",
    "\n",
    "# Other job parameters\n",
    "input_data_format = 'ONE_DOC_PER_LINE'\n",
    "job_uuid = uuid.uuid1()\n",
    "job_name = f\"events-job-{job_uuid}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_types = [\"BANKRUPTCY\", \"EMPLOYMENT\", \"CORPORATE_ACQUISITION\", \n",
    "               \"INVESTMENT_GENERAL\", \"CORPORATE_MERGER\", \"IPO\",\n",
    "               \"RIGHTS_ISSUE\", \"SECONDARY_OFFERING\", \"SHELF_OFFERING\",\n",
    "               \"TENDER_OFFERING\", \"STOCK_SPLIT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current job status\n",
    "job = comprehend_client.describe_events_detection_job(JobId=events_job_id)\n",
    "\n",
    "# Loop until the job is completed\n",
    "waited = 0\n",
    "timeout_minutes = 30\n",
    "while job['EventsDetectionJobProperties']['JobStatus'] != 'COMPLETED':\n",
    "    sleep(60)\n",
    "    waited += 60\n",
    "    assert waited//60 < timeout_minutes, \"Job timed out after %d seconds.\" % waited\n",
    "    print('.', end='')\n",
    "    job = comprehend_client.describe_events_detection_job(JobId=events_job_id)\n",
    "\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the job is complete, download the results in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output filename is the input filename + \".out\"\n",
    "output_data_s3_file = job['EventsDetectionJobProperties']['OutputDataConfig']['S3Uri'] + filename + '.out'\n",
    "\n",
    "# Load the output into a results dictionary\n",
    "results = []\n",
    "with smart_open.open(output_data_s3_file) as fi:\n",
    "    results.extend([json.loads(line) for line in fi.readlines() if line])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Amazon Comprehend Events system output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first results document for analysis\n",
    "result = results[0]\n",
    "raw_text = raw_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "result['Events'][1]['Triggers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Arguments are linked to entities by the EntityIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "result['Events'][1]['Arguments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Entities are groups of mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "result['Entities'][0]['Mentions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing the events and entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the output to the displaCy format\n",
    "entities = [\n",
    "    {'start': m['BeginOffset'], 'end': m['EndOffset'], 'label': m['Type']}\n",
    "    for e in result['Entities']\n",
    "    for m in e['Mentions']\n",
    "]\n",
    "\n",
    "triggers = [\n",
    "    {'start': t['BeginOffset'], 'end': t['EndOffset'], 'label': t['Type']}\n",
    "    for e in result['Events']\n",
    "    for t in e['Triggers']\n",
    "]\n",
    "\n",
    "# Spans need to be sorted for displaCy to process them correctly\n",
    "spans = sorted(entities + triggers, key=lambda x: x['start'])\n",
    "tags = [s['label'] for s in spans]\n",
    "\n",
    "output = [{\"text\": raw_text, \"ents\": spans, \"title\": None, \"settings\": {}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Miscellaneous objects for presentation purposes\n",
    "spectral = cm.get_cmap(\"Spectral\", len(tags))\n",
    "tag_colors = [colors.rgb2hex(spectral(i)) for i in range(len(tags))]\n",
    "color_map = dict(zip(*(tags, tag_colors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Note that only entities participating in events are shown\n",
    "displacy.render(output, style=\"ent\", options={\"colors\": color_map}, manual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rendering as tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Create the entity DataFrame. Entity indices must be explicitly created.\n",
    "entities_df = pd.DataFrame([\n",
    "    {\"EntityIndex\": i, **m}\n",
    "    for i, e in enumerate(result['Entities'])\n",
    "    for m in e['Mentions']\n",
    "])\n",
    "\n",
    "# Create the events DataFrame. Event indices must be explicitly created.\n",
    "events_df = pd.DataFrame([\n",
    "    {\"EventIndex\": i, **a, **t}\n",
    "    for i, e in enumerate(result['Events'])\n",
    "    for a in e['Arguments']\n",
    "    for t in e['Triggers']\n",
    "])\n",
    "\n",
    "# Join the two tables into one flat data structure\n",
    "events_df = events_df.merge(entities_df, on=\"EntityIndex\", suffixes=('Event', 'Entity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating a more succinct representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def format_compact_events(x):\n",
    "    \"\"\"Collapse groups of mentions and triggers into a single set.\"\"\"\n",
    "    # Take the most commonly occurring EventType and the set of triggers\n",
    "    d = {\"EventType\": Counter(x['TypeEvent']).most_common()[0][0],\n",
    "         \"Triggers\": set(x['TextEvent'])}\n",
    "    # For each argument Role, collect the set of mentions in the group\n",
    "    for role in x['Role']:\n",
    "        d.update({role: set((x[x['Role']==role]['TextEntity']))})\n",
    "    return d\n",
    "\n",
    "# Group data by EventIndex and format\n",
    "event_analysis_df = pd.DataFrame(\n",
    "    events_df.groupby(\"EventIndex\").apply(format_compact_events).tolist()\n",
    ").fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "event_analysis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Graphing event semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Entities are associated with events by group, not individual mention\n",
    "# For simplicity, aassume the canonical mention is the longest one\n",
    "def get_canonical_mention(mentions):\n",
    "    extents = enumerate([m['Text'] for m in mentions])\n",
    "    longest_name = sorted(extents, key=lambda x: len(x[1]))\n",
    "    return [mentions[longest_name[-1][0]]]\n",
    "\n",
    "# Set a global confidence threshold\n",
    "thr = 0.5\n",
    "\n",
    "# Nodes are (id, type, tag, score, mention_type) tuples\n",
    "trigger_nodes = [\n",
    "    (\"tr%d\" % i, t['Type'], t['Text'], t['Score'], \"trigger\")\n",
    "    for i, e in enumerate(result['Events'])\n",
    "    for t in e['Triggers'][:1]\n",
    "    if t['GroupScore'] > thr\n",
    "]\n",
    "entity_nodes = [\n",
    "    (\"en%d\" % i, m['Type'], m['Text'], m['Score'], \"entity\")\n",
    "    for i, e in enumerate(result['Entities'])\n",
    "    for m in get_canonical_mention(e['Mentions'])\n",
    "    if m['GroupScore'] > thr\n",
    "]\n",
    "\n",
    "# Edges are (trigger_id, node_id, role, score) tuples\n",
    "argument_edges = [\n",
    "    (\"tr%d\" % i, \"en%d\" % a['EntityIndex'], a['Role'], a['Score'])\n",
    "    for i, e in enumerate(result['Events'])\n",
    "    for a in e['Arguments']\n",
    "    if a['Score'] > thr\n",
    "]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Creating a compact graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# Iterate over triggers and entity mentions\n",
    "for mention_id, tag, extent, score, mtype in trigger_nodes + entity_nodes:\n",
    "    label = extent if mtype.startswith(\"entity\") else tag\n",
    "    G.add_node(mention_id, label=label, size=score*10, color=color_map[tag], tag=tag, group=mtype)\n",
    "    \n",
    "# Iterate over argument role assignments\n",
    "for event_id, entity_id, role, score in argument_edges:\n",
    "    G.add_edges_from(\n",
    "        [(event_id, entity_id)],\n",
    "        label=role,\n",
    "        weight=score*100,\n",
    "        color=\"grey\"\n",
    "    )\n",
    "\n",
    "# Drop mentions that don't participate in events\n",
    "G.remove_nodes_from(list(nx.isolates(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "nt = Network(\"600px\", \"800px\", notebook=True, heading=\"\")\n",
    "nt.from_nx(G)\n",
    "nt.show(\"compact_nx.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a more complete graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function in `events_graph.py` plots a complete graph of the document\n",
    "# The graph shows all events, triggers, entities, and their groups\n",
    "\n",
    "import events_graph as evg\n",
    "\n",
    "evg.plot(result, node_types=['event', 'trigger', 'entity_group', 'entity'], thr=0.5)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "python3",
   "version": "3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b71a13339a0be9489ff337af97259fe0ed71e682663adc836bae31ac651d564e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
